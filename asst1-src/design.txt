######################################
Part 1: Concurrent Mathematics Problem
######################################

The counter variable is a shared resource between the threads of execution.
As each of these threads require updating the counter, without the use
of synchronisation the operating system could for example interleave the
instructions such that `counter = counter + 1` is executed in multiple
threads before the instruction `b = counter` is executed, leaving an unexpected
value in b.

To prevent concurrent (unsafe) modification of the counter variable, we employed
the use of a lock to achieve mutual exclusion (made available through the OS/161
locking primitives). We identified the critical section in adder() beginning
from the assignment `a = counter` and ending at the end of the if/else block.
Accordingly, we acquire the lock prior to entry of the critical region and
release the lock after execution of the critical region has finished. Since our
lock needed to be used in every adder() thread, our lock was created in the
maths() function and destroyed after all the adder() threads terminated.

#######################
Part 2: Simple Deadlock
#######################

In the original code, bill() and ben() are called in separate threads
and acquire the same two locks in the reverse order. This causes a deadlock
for example, when the following interleaving occurs:

bill's thread          | ben's thread
1: lock_acquire(locka) |
2:                     | lock_acquire(lockb)
3: lock_acquire(lockb) |
4:                     | lock_acquire(locka)

This occurs since bill's thread is waiting for lockb to be released (which ben
currently has), and ben's thread is waiting for locka to be released (which bill
currently has). As each thread is waiting for the other to release a requested
resource, a deadlock occurs.

We used the prevention strategy to deal with the deadlock, removing the circular
wait condition by ordering the resource requests such that the threads acquire
the locks in the same order. This solution ensures that the first lock is
required to be held by a thread before the second lock can be acquired. As such,
neither thread can acquire a lock that the other thread will need if the other
thread has already acquired one of its locks.

With this request ordering, there are four possible interleavings of requests:

Case 1: One of the threads requests (and acquires) both locks before the other
thread. When the other thread requests locka, it blocks until the first thread
releases locka. Since the first thread has access to all the resources it
requires, it will eventually complete and release its resources for the other
thread to use.

bill's thread          | ben's thread
1: lock_acquire(locka) |
2: lock_acquire(lockb) |
3:                     | lock_acquire(lock_a)
4:                     | lock_acquire(lock_b)

OR

bill's thread          | ben's thread
1:                     | lock_acquire(locka)
2:                     | lock_acquire(lockb)
3: lock_acquire(locka) |
4: lock_acquire(lockb) |

Case 2: One of the threads requests (and acquires) locka, then the other thread
requests locka and blocks (as the first thread is holding it). The first thread
proceeds to acquire lockb. Again, the first thread has access to all the
resources it requires, so it will eventually complete and release its resources
for the other thread to use.

bill's thread          | ben's thread
1: lock_acquire(locka) |
2:                     | lock_acquire(lock_a)
3: lock_acquire(lockb) |
4:                     | lock_acquire(lock_b)

OR

bill's thread          | ben's thread
1:                     | lock_acquire(locka)
2: lock_acquire(locka) |
3:                     | lock_acquire(lockb)
4: lock_acquire(lockb) |

################################################
Part 3: Bounded Buffer Producer/Consumer Problem
################################################

- The buffer used by the producer and consumer consists of a fixed-size array
  and two indexes, `head` (referring to the first item for consumption) and
  `tail` (referring to the next available slot for production).
- We used a lock (buffer_lock) to restrict access to the buffer (a shared
  resource between producer/consumer threads). Any time that the buffer is
  modified (producer produces an item or consumer consumes an item), the lock is
  used to ensure mutual exclusion.
- We used two condition variables:
  - has_capacity: to track whether the buffer has at least one free slot
  - has_data: to track whether the buffer has at least one item available for
    consumption
- Consumer waits on has_data, sleeping if there are no items available to
  consume. Signals has_capacity once it finishes consuming an item by adjusting
  the head pointer.
- Producer waits on has_capacity, sleeping if there is no space in the buffer to
  produce items. Signals has_data once it finishes producing an item by adding
  it to the end of the queue and adjusting the tail pointer.
- An alternative solution is to use semaphores in place of condition variables.
  However, for the sake of code clarity, it was decided to use condition
  variables.

###########################
Part 4: Bar Synchronisation
###########################

At a high-level, this problem is essentially a more involved producer-consumer
scenario in which the producers are customers who order drinks and the
consumers are the bartenders, who serve the customers.

Once a drink is ordered by a customer, order_drink() is called. Since this
function is executed by a producer thread (customer), in order to notify a
consumer thread (i.e. a bartender) that a drink has been ordered, a condition
variable (`order_made`) is used. Consumers wait on this condition in
take_order(). The order is passed to the consumer from the producer through
the use of a global queue of orders `pending orders`. Since access to this
queue is made by concurrent threads, mutual exclusion is achived through the
use of a lock `que_lock`, acquired and released before and after enqueuing
and dequeuing.

To acheive the requirement that customers block until the order is ready,
a semaphore was used. This semaphore was added to `struct barorder` so that
P() and V() could be executed from any function with access to the specific
order. In order_drink(), we create the semaphore and decrement using P(),
which blocks until the order is "ready". In the consumer thread, once the
order is ready, serve_order() is called, which invokes V() on the semaphore,
allowing the producer thread to wakeup.

The fill_order() function can be thought of as a wrapper to the mix() function
in that it simply achieved deadlock-free mutual exclusion with respect to the
bottles used to mix the drink. Since the mix() function increments the number
of doses for up to DRINK_COMPLEXITY bottles used in the drink, fill_order()
only needs to acquire and release locks on those specific bottles before and
after calling mix() to achive mutual exclusion. To achieve this requirement,
we created a global bottle_locks array to store locks for up to NBOTTLES and
in fill_order(), we examined the requested_bottles in the order, acquiring
locks on only those bottles.

Since a particular order may require multiple locks to be obtained for
bottles in fill_order(), we had to employ a deadlock prevention scheme
to avoid potential deadlock due to cyclic wait conditions. To do this,
we sort the order->requested_bottles array before acquiring the bottle
locks needed for the order. This ensures that all threads acquire the locks
in the same order, thus adhering to the resource ordering convention.

Finally, our solution ensures that all locks, semaphores and condition
variables used are appropriately freed. Our bar_open() function initially
creates the global locks, including one for each of the bottles and our
bar_close() correspondingly destroys these synchronisation primitives.
